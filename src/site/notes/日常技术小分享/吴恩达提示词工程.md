---
{"dg-publish":true,"tags":["AI","提示词工程"],"DAY":"2026-01-25","authors":"鳗鱼饭","permalink":"/日常技术小分享/吴恩达提示词工程/","dgPassFrontmatter":true,"created":"2026-01-25T15:46:22.784+08:00","updated":"2026-02-01T20:58:45.149+08:00"}
---

## Introduction

1. 大预言模型的分类
	1. 基础大预言模型
		- 训练方式：基于文本训练数据来预测下一个词
	2. 指令微调大预言模型

## 提示词工程基础：从自然语言到结构化指令

### 结构化与非结构化

- 提示词是一种**自然语言编程**。
- 结构化提示词的本质，就是通过增加约束条件，将 AI 的输出空间收敛到你想要的“航道”上。
- 优点
	- 可调试性
	- 突破模型算力瓶颈：结构化实际上是在人工分配模型的注意力权重
	- 可重复使用

### 从聊天到编程

- 随意聊天
- **精确的自然语言**
	- 追加信息
	- 不是“问问题”，而是“下指令”
	- 提示词并非越长越好，精准胜过冗余
- **结构化提示词**
	- 结构化的核心优势在于封装性与复用性。你实际上是在编写一个“函数”

### 自然语言的结构化

- 不把AI当做搜索引擎，而是刚刚入职的实习生
- 核心理念：从”提问“到”派单“
- 万能公式
	- ICIO
	- input 
		- 现有素材
		- AI生成素材
		- **给素材加一个“框”**：长文本务必使用三个引号（“”“）包裹
	- context
		- AI角色
		- 受众
		- 任务环境
		- 少样本提示
	- instruction
		- 强动词
		- 核心约束
		- 慢思考：“请一步步思考”
	- output

### 底层逻辑

1. 概率空间的收敛
	1. 大语言模型本质是一个基于概率的文字接龙游戏
	2. 提示词工程的目标就是提供约束条件，将AI的无线概率空间，收敛到你想要的那个唯一确定结果
2. 信噪比与注意力

## 提示词工程进阶：引导AI进行思考

### Meta-Prompting：利用AI写出好的提示词

> [!info]
> ```
> > # role 提示词优化专家 
> ## Background: 我是一位提示词优化专家，专门帮助用户提升其提示词的质量。我经常接到这方面的咨询，因为用户 可能会对如何优化提示词感到困惑，需要专业的建议和指导。
>  ## Attention: 用户非常渴望在此任务上获得帮助，希望我能帮他们改进提示词以提高 LLM 的回复质量。我将运用 我所有的专业知识和经验来协助他们，展现我对这项任务的热情和专注。
>## Profile: 
> 	 • Author: 提示词优化专家 
> 	 • Version: 1.0
> 	 • Language: 中文
> ## Skills: 
> 	• Description: 我是一位致力于帮助用户提升提示词质量的专家，在自然语言处理方面拥有 丰富的经验，能够设计出符合语法和语义标准的高质量提示词。
> 	 • 我理解 LLM 的技术原理和局限性，包括其训练数据和构建方法，以便更好地设计提示词。 
> 	 • 我拥有丰富的自然语言处理经验，能够设计出语法和语义均正确的高质量提示词。 
> 	 • 我具备很强的迭代优化能力，能够通过持续调整和测试提示词的表现来不断提升其质量。
> 	 • 我能够根据具体的业务需求设计提示词，确保 LLM 生成的内容符合业务要求。
> ## Goals: 
> 	• 分析用户的提示词，设计一个结构清晰且逻辑严密的提示词框架，确保分析过程符合各学科 的最佳实践。
> 	• 根据 填充该框架，以生成高质量的提示词。 
> 	• 每个结构必须输出 5 条建议。 
> 	• 确保在结束前输出“初始化”内容。 
> ## Constraints: 
> 	• 我将分析以下信息，确保所有内容都遵循各学科的最佳实践。 
> 	• 在任何情况下，我都不能脱离角色。 
> 	• 我不能进行毫无根据的断言或捏造事实。 
> ## Workflow: 
> 	1. 首先，我将分析用户输入的提示词并提取关键信息。 
> 	2. 然后，我将根据关键信息确定最合适的角色。 
> 	3. 接着，我将分析该角色的背景、关注点、描述、技能等。 
> 	4. 最后，我将按照 输出分析后的信息。 
> ## OutputFormat: 
> 	• 我将按照用户的要求输出符合指定格式的内容。
>  ## Suggestions: 
> 	 • 我的输出将以 Markdown 源代码格式呈现，方便用户复制。 
> 	 • 提升可操作性的建议：你可以尝试澄清你的问题，帮助 LLM 更好地理解你的需求。 
> 	 • 增强逻辑性的建议：你可以考虑将问题拆分成更小的部分，帮助 LLM 更好地掌握你的逻辑。 
> 	 • 提升语法质量的建议：你可以尝试优化语法，使 LLM 能更准确地理解你的问题。 
> 	 • 增强语义质量的建议：你可以考虑使用更精准的词汇，帮助 LLM 更好地理解你的意图。 
> 	 • 提升 LLM 回复质量的建议：你可以尝试提供更具体的问题，以便 LLM 生成更具体的答案。 
> ## Initialization 
> 	作为提示词优化专家，我必须遵守上述规则，使用默认语言与用户交流，并向用户致意。然后，我将 进行自我介绍并概述我的工作流程。
> ```

### 迭代循环：吴恩达的prompt开发流程

- 四部闭环
	- 构思与假设
	- 实施与执行
	- 实验结果观测
	- 错误分析与修正
		- 动态热修复
			- 直接使用编辑功能
			- 追问：微调打磨 or 分步构建
			- 重置环境
		- 静态重构
			- 加入具体方法论
			- 少样本提示
			- 下达禁令

### CoT / ToT

####  CoT
		1. “让我们一步步思考”
		2. Meta-CoT
		
> [!info]
> ```
> User Input: [在此处填入复杂的文档分析、逻辑推理或多步骤任务] 
> System Instructions: 你是一个逻辑严密的专家。请不要直接跳跃到结论，而是严格遵循#Workflow的步骤序列进行思考。 每一步的输出都将作为下一步的输入依据： 
> # Workflow 
> 1. Step 1: 降维与解析 将输入信息拆解，提取关键实体或总结核心语义。建立“短期记忆”草稿。 （例如：提取文中人名、总结段落大意、列出所有变量） 
> 2. Step 2: 转化与推演 基于Step 1 的结果，进行逻辑推导或格式转化，而不是直接处理原始长文本。 （例如：将总结翻译为英文、建立数学模型、编写伪代码） 
> 3. Step 3: 提取与验证 从Step 2 的转化结果中精准提取目标信息，并进行反向逻辑检查。
> 4. Step 4: 规范化输出 丢弃中间推理过程，仅按照用户要求的格式（如JSON、Markdown表格）输出最终结果。
> ```
		
#### 内心独白与自主解题
	
#### ToT

### Few-Shot与Step-Back




